a <- available.packages()
a
head(rownames(a),3)
library(ggplot2)
install.pages("ggplot2")
install.packages("ggplot2")
library(ggplot2)
search()
x <- 4
x.class()
class(x)
x <- c(4, "a", TRUE
x
x <- c(4, "a", TRUE)
x
class(x)
x <- c(1,3, 5)
y <- c(3, 2, 10)
rbind(x,y)
x <- 1:4
y <- 2
x+ y
x <- c(17, 14, 4, 5, 13, 12, 10)
x[x>10] <- 4
x
data <- read.table('hw1_data.csv')
data <- read.table('hw1_data.csv')
data <- read.table('hw1_data.csv')
data <- read.table('hw1_data.csv')
data <- read.csv('hw1_data.csv')
data
data[1:]
dim(data)
mean(data)
x[1,]
data[1,]
data[,1]
data[,1]!=NA
data[,1]
bad <- is.na(data[,1])
data[,1]
data[,1][!bad]
mean(data[,1][!bad])
data[,1]
data[1,]
data[1,][>31]
data[1,][data > 31]
data[data> 31]
data[1,]
data[,1][data>31]
data[,1]
data[,1>31]
data[,1>31;,5>90]
data[,1>31;][,5>40]
data[data[,1]>40]
data
data[data[,1]]
data[ data[,1]>40 ]
data[ data[,1] > 40 ]
dim(data)
data[1]
data[ data[,2] > 40 ]
data[1]>40
data[data[1]>40]
data[data[1,]>40]
data[data[,1]>40]
data[data[1,]>40]
data[1]
data[1]>40
data[,1]
data[1,]
data[,1]>40
data[data[,1]>40]
data[(data[,1]>40)]
m = c(data)
m
dim(c)
dim(m)
class(m)
class(data)
m <- 1:10
class(m)
x <- matrix(1:6, 2, 3)
class(x)
x
m = matrix(data)
m
subset_1 <- subset (data, Ozone>41)
subset_1
subset_1 <- subset (data, Ozone>11 & Temop>90 )
subset_1 <- subset (data, Ozone>11 & Temp>90 )
subset_1
subset_1[,2]
mean(subset_1[,2])
subset_2 <- subset (data, Month == 6)
subset_2
mean(subset_2[,5])
mean(subset_2[,4])
subset_3 <- subset (data, Month == 5)
max(subset_3[,1])
subset_3
subset_3[,1]
max(subset_3[,1])
subset_3 <- subset (data, Month == 5, Ozone != NA)
subset_3 <- subset (data, Month == 5, Ozone >0)
subset_3
subset_3 <- subset (data, Month == 5, Ozone >10)
subset_3
subset_3 <- subset (data, Month == 5)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone != NA)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone == 41)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone > 0)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone > 0)
max(subset_3)
max(subset_3[,1])
library("rhdf5", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
created = h5createFile("example.h5")
created
created = h5createFile("example.h5")
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A,"example.h5","foo/A")
B = array(seq(0.1,2.0,by=0.1),dim=c(5,2))
attr(B,"scale") <- "liter"
h5write(B,"example.h5","foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L,seq(0,1,length.out=5),c("ab","cde","fghi","a","s"),stringAsFactors=FALSE)
h5write(df,"example.h5","df")
h5ls("example.h5")
readA = h5read("example.h5","foo/A")
readA = h5read("example.h5","foo/foobaa/B")
readdf = h5read("example.h5","df")
readA
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html,"//title",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
library(httr)
install.packages("httr")
install.packages("httr")
library(httr)
html2 = GET(url)
content2 = content(html2,as="text")
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(html,"//title",xmlValue)
pg2 = GET("http://http://httpbin.org/basic-auth/user/passwd")
authenticate("user","passwd")
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd")
authenticate("user","passwd")
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd"),authenticate("user","passwd"))
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd"))
pg2
google = handle("http://google.com")
pg1 = GET(handle=google,path="/")
pg2 = GET(handle=google,path="search")
pg1
pg2
myapp = oauth_app("twitter",key="4tRDkZMRxMd3msSEOiNFkQ",secret="aUqkQiRKPXRXIKyRdv64eVug5avgbmHPmkK6ews")
sig = sign_oauth1.0(myapp,token="51395803-hSMhx8QZA23TDT1NVRhllRnHgCRvnJHlgnh5rQKNC",token_secret="i2yrI5NH7O3Nkod45TJLg6DAZ5MNDH5n8HQchp5P55FRe")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
homTL
homeTL
json1 = content(homeTL)
json2 = jsonLite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
install.packages("jsonlite")
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json1
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
install.packages("rjson")
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2 = jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
options(gsubfn.engine = "R")
require(sqldf)
setwd("~/Desktop/Coursera/Data_Science/datasciencecoursera/Class_3")
temp <- readLines("ncep.for", n = 6)
temp
temp <- readLines("ncep.for", widths=c(9,4,3,4,3,4,3,4,3))
temp <- read.fwf("ncep.for", widths=c(9,4,3,4,3,4,3,4,3))
temp
temp[1]
temp <- read.fwf("ncep.for", widths=c(10,4,3,4,3,4,3,4,3))
temp
temp[1]
temp[1]
temp[1]
temp[2]
temp[3]
temp <- read.fwf("ncep.for", widths=c(14,4,9,4,9,4,9,4,9))
temp
temp <- read.fwf("ncep.for", widths=c(14,4,8,4,9,4,9,4,9))
temp
temp <- read.fwf("ncep.for", widths=c(14,3,8,4,9,4,9,4,9))
temp
temp <- read.fwf("ncep.for", widths=c(9,-5,4,4,-5,4,4-5,4,4,-5,4,4))
temp
temp[2]
temp[1]
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4-5,4,4,-5,4,4))
temp
temp[4]
sum(temp[4])
class(temp[4])
names(temp[3])
sum(temp$V3)
sum(temp$V4)
temp[4]
temp[4][1]
temp[4][1,]
temp[4,1]
temp[1,4]
temp[4]
temp[1]
temp[6]
temp[8]
temp[2]
temp[3]
temp[4]
temp[5]
temp[6]
temp[3][5]
temp[3]
temp[3][1,5]
temp[3][1,6]
temp[3][4,1]
temp[3][1,1]
temp[3]
dim(temp[3])
temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4-5,4,4,-5,4,4))
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4))
temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4)); temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,4,4)); temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4)); temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4)); temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4)); temp
temp <- read.fwf("ncep.for", widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4)); temp
temp[3]
names[temp]
names(temps)
names(temp)
temp['V1']
sum(temp$V1)
temp[4]
colSums(temp[4])
temp[1,4]
class(temp[1,4])
class(temp[4])
colSums(temp[,-1])
x <- read.fwf(
file=url("http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for"),
skip=4,
widths=c(12, 7,4, 9,4, 9,4, 9,4))
x
x[4]
sum(x[4])
sum(x[1])
sum(x[2])
head(x)
temp <- read.fwf("ncep.for", skip=4,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4)); temp
sum(temp[4])
sum(x[4])
sum(x[9])
sum(x[8])
sum(x[7])
sum(x[6])
sum(x[5])
sum(x[4])
sum(x[3])
sum(x[2])
sum(x[1])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for", destfile = "ncep.for", method = "curl")
temp <- read.fwf("ncep.for", skip=4,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4)); temp;
sum(temp[4])
