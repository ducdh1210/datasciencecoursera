mean(subset_2[,5])
mean(subset_2[,4])
subset_3 <- subset (data, Month == 5)
max(subset_3[,1])
subset_3
subset_3[,1]
max(subset_3[,1])
subset_3 <- subset (data, Month == 5, Ozone != NA)
subset_3 <- subset (data, Month == 5, Ozone >0)
subset_3
subset_3 <- subset (data, Month == 5, Ozone >10)
subset_3
subset_3 <- subset (data, Month == 5)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone != NA)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone == 41)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone > 0)
subset_3
subset_3 <- subset (data, Month == 5 & Ozone > 0)
max(subset_3)
max(subset_3[,1])
library("rhdf5", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
created = h5createFile("example.h5")
created
created = h5createFile("example.h5")
created = h5createGroup("example.h5","foo")
created = h5createGroup("example.h5","baa")
created = h5createGroup("example.h5","foo/foobaa")
h5ls("example.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A,"example.h5","foo/A")
B = array(seq(0.1,2.0,by=0.1),dim=c(5,2))
attr(B,"scale") <- "liter"
h5write(B,"example.h5","foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L,seq(0,1,length.out=5),c("ab","cde","fghi","a","s"),stringAsFactors=FALSE)
h5write(df,"example.h5","df")
h5ls("example.h5")
readA = h5read("example.h5","foo/A")
readA = h5read("example.h5","foo/foobaa/B")
readdf = h5read("example.h5","df")
readA
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5","foo/A")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
library(XML)
url <- "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html,"//title",xmlValue)
xpathSApply(html,"//td[@id='col-citedby']",xmlValue)
library(httr)
install.packages("httr")
install.packages("httr")
library(httr)
html2 = GET(url)
content2 = content(html2,as="text")
parsedHtml = htmlParse(content2,asText=TRUE)
xpathSApply(html,"//title",xmlValue)
pg2 = GET("http://http://httpbin.org/basic-auth/user/passwd")
authenticate("user","passwd")
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd")
authenticate("user","passwd")
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd"),authenticate("user","passwd"))
pg2
pg2 = GET("http://httpbin.org/basic-auth/user/passwd",authenticate("user","passwd"))
pg2
google = handle("http://google.com")
pg1 = GET(handle=google,path="/")
pg2 = GET(handle=google,path="search")
pg1
pg2
myapp = oauth_app("twitter",key="4tRDkZMRxMd3msSEOiNFkQ",secret="aUqkQiRKPXRXIKyRdv64eVug5avgbmHPmkK6ews")
sig = sign_oauth1.0(myapp,token="51395803-hSMhx8QZA23TDT1NVRhllRnHgCRvnJHlgnh5rQKNC",token_secret="i2yrI5NH7O3Nkod45TJLg6DAZ5MNDH5n8HQchp5P55FRe")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json",sig)
homTL
homeTL
json1 = content(homeTL)
json2 = jsonLite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
install.packages("jsonlite")
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSon(toJSON(json1))
json2[1,1:4]
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json1
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
install.packages("rjson")
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
json2 = jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1,1:4]
options(gsubfn.engine = "R")
require(sqldf)
x <- matrix(rnorm(200), 20, 10)
apply(x,2,mean)
apply(x,1,sum)
apply (x, 1, quantile, probs=(c(0.25,0.75)))
a <- array(rnorm(2*2*10), c(2,2,10))
apply(a, c(1,2), mean)
a
dim(a)
x <- c (rnorm(10), runif(10), rnorm(10,1))
x
f <- gl(3,10)
f
tapply(x,f,mean)
tapply(x,f,mean,simplify=FALSE)
tapply(x,f,mean)
tapply(x,f,range)
x <- c (rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10) # f is a factor, whose has 3 levels and each level is repeated 10 times
split(x,f)
k <- split(x,f)
class(k)
k[1]
k['1']
k[1,]
x <- c (rnorm(10), runif(10), rnorm(10,1))
f <- gl(3,10) # f is a factor, whose has 3 levels and each level is repeated 10 times
lapply(split(x,f), mean)
library(dataset)
library(datasets)
head(airquality)
library(datasets)
head(airquality)
data = head(airquality)
data
class(data)
data[3]
data$Month
class(data$Month)
f <- gl(3,10)
class(f)
airquality$Month
class(airquality$Month)
s <- split(airquality, airquality$Month)
lapply(s, function(x) colMeans(x[,"Ozone","Solar.R","Wind"]))
s <- split(airquality, airquality$Month)
lapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")]))
sapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")]))
sapply(s, function(x) colMeans(x[,c("Ozone","Solar.R","Wind")], na.rm=TRUE))
x <- rnorm(10)
f1 <- gl(2,5)
f2 <- gl(5,2)
f1
f2
interaction(f1,f2)
interaction(f1,f2)
interaction(f1,f2)
str(split(x,list(f1,f2)))
str(split(x,list(f1,f2),drop=TRUE))
noise <- function(n,mean,sd){
rnorm(n,mean,sd)
}
noise(5,1,2)
mapply(noise,1:5,1:5,2)
log(-1)
printmessage <- function(x){
if (x>0){
print("x is greater than zero")
}else{
print("x is less than zero")
}
invisible(x)
}
printmessage(10)
printmessage <- function(x){
if (x>0)
print("x is greater than zero")
else
print("x is less than zero")
invisible(x)
}
printmessage(10)
printmessage(NA)
printmessage <- function(x){
if (is.na(x))
print("x is a missing value")
else if (x>0)
print("x is greater than zero")
else
print("x is less than zero")
invisible(x)
}
printmessage(NA)
mean(x)
mean(adfadf)
traceback()
lm(adf-uhn)
traceback(0)
traceback()
debug(lm)
lm(k-o)
Q
ls
debug(ls)
ls()
library(reshape2)
head(mtcars)
mtcars$carname <-rownames(mtcars)
mtcars$carname
rownames(mtcars)
carMelt <- melt(mtcars,id=c("carname","gear","cycl"),measure.vars=c("mpg","hp"))
carMelt <- melt(mtcars,id=c("carname","gear","cyl"),measure.vars=c("mpg","hp"))
View(mtcars)
View(mtcars)
View(carMelt)
View(mtcars)
cylData <- dcast(carMelt, cyl ~ variable)
View(cylData)
View(carMelt)
View(mtcars)
cylData <- dcast(carMelt, cyl ~ variable, mean)
View(cylData)
head(InsectSprays)
tapply(InsectSprays$count, InsectSprays$spray, sum)
as.numeric(yesnofac)
spIns = split(InsectSprays$count, InsectSprays$spray)
spIns
sprCount = lapply(spIns, sum)
unlist(sprCount)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
source('~/.active-rstudio-document', echo=TRUE)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
install.packages("plyr")
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
library(plyr)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
library(plyr)
ddply(InsectSprays,.(spray),summarise,sum=sum(count))
ddply(InsectSprays,.(spray),summarise,sum=ave(count,FUN=sum))
fileUrl1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solution-apr29.csv"
download.file(fileUrl1, destfile="reviews.csv",method="curl")
download.file(fileUrl2, destfile="solutions.csv",method="curl")
reviews <- read.csv("reviews.csv")
solutions <- read.csv("solutions.csv")
head(reviews,2)
head(solutions,2)
fileUrl2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileUrl2, destfile="solutions.csv",method="curl")
solutions <- read.csv("solutions.csv")
head(solutions,2)
head(reviews,2)
names(reviews)
names(solutiona)
names(solutions)
mergedData = merge(reviews, solutions, by.x="solution_id", by.y="id",all=TRUE)
head(mergedData)
View(reviews)
View(solutions)
intersect(names(solutions),names(reviews))
mergedData2 = merge(reviews,solutions,all=TRUE)
head(mergedData2)
df1 = data.frame(id=sample(1:10),x=rnorm(10))
df2 = data.frame(id=sample(1:10),y=rnorm(10))
arrange(join(df1,df2),id)
df3 = data.frame(id=sample(1:10),y=rnorm(10))
dfList = list(df1, df2, df3)
join_all(dfList)
df3 = data.frame(id=sample(1:10),z=rnorm(10))
dfList = list(df1, df2, df3)
join_all(dfList)
##############################################################
# STEP 2: Read tables (df_ refers to dataframe)
# read activity labels
df_activity <- read.table(file="./UCI HAR Dataset/activity_labels.txt")
# read the features (measurement names)
df_features <- read.table(file="./UCI HAR Dataset/features.txt")
# read the subject data (indicating participant)
df_subj_train <- read.table(file="./UCI HAR Dataset/train/subject_train.txt")
df_subj_test <- read.table(file="./UCI HAR Dataset/test/subject_test.txt")
# read the observation data (values for row)
df_x_train <- read.table(file="./UCI HAR Dataset/train/X_train.txt")
df_x_test <- read.table(file="./UCI HAR Dataset/test/X_test.txt")
# read the label data (activity labels for column names)
df_y_train <- read.table(file="./UCI HAR Dataset/train/y_train.txt")
df_y_test <- read.table(file="./UCI HAR Dataset/test/y_test.txt")
##############################################################
# STEP 3: row binding (subject train, subjest test), (X_train, X_test), (Y_Train, Y_Test)
df_subj = rbind(df_subj_train, df_subj_test)
df_x = rbind(df_x_train, df_x_test)
df_y = rbind(df_y_train, df_y_test)
# in df_y, convert numeric value to activity name
df_y$V1 <- factor(df_y$V1, df_activity[,1], df_activity[,2])
##############################################################
# STEP 4: from feature table, get and clean feature labels relating to mean and std
# get a factor, which is the second column of df_features
ft_feature <- df_features[,2];
# create a vector whose each element is the index of the row referring to a mean measure
vt_mean <- grep("-mean()", fixed=TRUE, ft_feature)
# create a vector whose each element is the index of the row referring to a mean measure
vt_std <-  grep("-std()", fixed=TRUE, ft_feature)
# combining those two above vectors and sort the indexes
vt_col <- c(vt_mean,vt_std)
vt_col <- sort(vt_col)
# keep only labels which contains "mean" and "std" in its name
ft_feature <- ft_feature[vt_col];
##############################################################
# STEP 5: Refine dataset df_x and add subject and activity columns to it
# refine df_x so that it only contains columns refering measures of mean or std
df_x <- df_x[,vt_col]
# add subject and activity columns to df_x
df_General <- cbind(df_subj, df_y, df_x)
##############################################################
# STEP 6: Add header to the dataset
# header of the first two columns are Subject and Activity
colnames(df_General)[1:2]<-c('Subject', 'Activity')
# from 3rd column to the last column, the headers are obtained from ft_feature
colnames(df_General)[3:length(df_General)] <- as.character(ft_feature)
##############################################################
# *STEP 7: Data Analysis --> find mean based on subject and activity
# load data table package
library(data.table)
# create data table variabel from df_General
dt_General <- data.table(df_General)
# take all columns except first two, split them by the couple (Subject - Activity), and find mean to each splitted group
# credit to: http://lamages.blogspot.com/2012/01/say-it-in-r-with-by-apply-and-friends.html
dt_Refined_General <- dt_General[,lapply(.SD,mean),by="Subject,Activity",.SDcols=3:length(dt_General)]
# reorder the rows based on Subject - Activity
dt_Refined_General <- dt_Refined_General[order(dt_Refined_General$Subject,dt_Refined_General$Activity),]
##############################################################
# STEP 8: Write to .txt file
write.table(dt_Refined_General, "tidy_data.txt", sep="\t", row.names = F, col.names = T)
setwd("~/Desktop/Coursera/Data_Science_PR/CleanData_PeerReview")
##############################################################
# STEP 2: Read tables (df_ refers to dataframe)
# read activity labels
df_activity <- read.table(file="./UCI HAR Dataset/activity_labels.txt")
# read the features (measurement names)
df_features <- read.table(file="./UCI HAR Dataset/features.txt")
# read the subject data (indicating participant)
df_subj_train <- read.table(file="./UCI HAR Dataset/train/subject_train.txt")
df_subj_test <- read.table(file="./UCI HAR Dataset/test/subject_test.txt")
# read the observation data (values for row)
df_x_train <- read.table(file="./UCI HAR Dataset/train/X_train.txt")
df_x_test <- read.table(file="./UCI HAR Dataset/test/X_test.txt")
# read the label data (activity labels for column names)
df_y_train <- read.table(file="./UCI HAR Dataset/train/y_train.txt")
df_y_test <- read.table(file="./UCI HAR Dataset/test/y_test.txt")
##############################################################
# STEP 3: row binding (subject train, subjest test), (X_train, X_test), (Y_Train, Y_Test)
df_subj = rbind(df_subj_train, df_subj_test)
df_x = rbind(df_x_train, df_x_test)
df_y = rbind(df_y_train, df_y_test)
# in df_y, convert numeric value to activity name
df_y$V1 <- factor(df_y$V1, df_activity[,1], df_activity[,2])
##############################################################
# STEP 4: from feature table, get and clean feature labels relating to mean and std
# get a factor, which is the second column of df_features
ft_feature <- df_features[,2];
# create a vector whose each element is the index of the row referring to a mean measure
vt_mean <- grep("-mean()", fixed=TRUE, ft_feature)
# create a vector whose each element is the index of the row referring to a mean measure
vt_std <-  grep("-std()", fixed=TRUE, ft_feature)
# combining those two above vectors and sort the indexes
vt_col <- c(vt_mean,vt_std)
vt_col <- sort(vt_col)
# keep only labels which contains "mean" and "std" in its name
ft_feature <- ft_feature[vt_col];
##############################################################
# STEP 5: Refine dataset df_x and add subject and activity columns to it
# refine df_x so that it only contains columns refering measures of mean or std
df_x <- df_x[,vt_col]
# add subject and activity columns to df_x
df_General <- cbind(df_subj, df_y, df_x)
##############################################################
# STEP 6: Add header to the dataset
# header of the first two columns are Subject and Activity
colnames(df_General)[1:2]<-c('Subject', 'Activity')
# from 3rd column to the last column, the headers are obtained from ft_feature
colnames(df_General)[3:length(df_General)] <- as.character(ft_feature)
##############################################################
# *STEP 7: Data Analysis --> find mean based on subject and activity
# load data table package
library(data.table)
# create data table variabel from df_General
dt_General <- data.table(df_General)
# take all columns except first two, split them by the couple (Subject - Activity), and find mean to each splitted group
# credit to: http://lamages.blogspot.com/2012/01/say-it-in-r-with-by-apply-and-friends.html
dt_Refined_General <- dt_General[,lapply(.SD,mean),by="Subject,Activity",.SDcols=3:length(dt_General)]
# reorder the rows based on Subject - Activity
dt_Refined_General <- dt_Refined_General[order(dt_Refined_General$Subject,dt_Refined_General$Activity),]
##############################################################
# STEP 8: Write to .txt file
write.table(dt_Refined_General, "tidy_data.txt", sep="\t", row.names = F, col.names = T)
install.packages("data.table")
setwd("~/Desktop/Coursera/Data_Science_PR/GetCleanData_PeerReview")
##############################################################
# NAME: Duc Do                                               #
# CLASS: Coursera, Data Science: Getting and Cleaning Data   #
# Course Project (Peer Review)                               #
# May 24, 2014                                               #
##############################################################
#install.packages("data.table")
##############################################################
# STEP 1: Download and unzip files
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(url,destfile="dataset.zip",method="curl")
unzip(zipfile="dataset.zip")
##############################################################
# STEP 2: Create tables from .txt files(df_ refers to dataframe)
# read activity labels
df_activity <- read.table(file="./UCI HAR Dataset/activity_labels.txt")
# read the features (measurement names)
df_features <- read.table(file="./UCI HAR Dataset/features.txt")
# read the subject data (indicating participant)
df_subj_train <- read.table(file="./UCI HAR Dataset/train/subject_train.txt")
df_subj_test <- read.table(file="./UCI HAR Dataset/test/subject_test.txt")
# read the observation data (values for row)
df_x_train <- read.table(file="./UCI HAR Dataset/train/X_train.txt")
df_x_test <- read.table(file="./UCI HAR Dataset/test/X_test.txt")
# read the label data (activity labels for column names)
df_y_train <- read.table(file="./UCI HAR Dataset/train/y_train.txt")
df_y_test <- read.table(file="./UCI HAR Dataset/test/y_test.txt")
##############################################################
# STEP 3: row binding (subject train, subjest test), (X_train, X_test), (Y_Train, Y_Test)
df_subj = rbind(df_subj_train, df_subj_test)
df_x = rbind(df_x_train, df_x_test)
df_y = rbind(df_y_train, df_y_test)
# in df_y, convert numeric value to activity name
df_y$V1 <- factor(df_y$V1, df_activity[,1], df_activity[,2])
##############################################################
# STEP 4: from feature table, get and clean feature labels relating to mean and std
# get a factor, which is the second column of df_features
ft_feature <- df_features[,2];
# create a vector whose each element is the index of the row referring to a mean measure
vt_mean <- grep("-mean()", fixed=TRUE, ft_feature)
# create a vector whose each element is the index of the row referring to a mean measure
vt_std <-  grep("-std()", fixed=TRUE, ft_feature)
# combining those two above vectors and sort the indexes
vt_col <- c(vt_mean,vt_std)
vt_col <- sort(vt_col)
# keep only labels which contains "mean" and "std" in its name
ft_feature <- ft_feature[vt_col];
##############################################################
# STEP 5: Refine dataset df_x and add subject and activity columns to it
# refine df_x so that it only contains columns refering measures of mean or std
df_x <- df_x[,vt_col]
# add subject and activity columns to df_x
df_General <- cbind(df_subj, df_y, df_x)
##############################################################
# STEP 6: Add header to the dataset
# header of the first two columns are Subject and Activity
colnames(df_General)[1:2]<-c('Subject', 'Activity')
# from 3rd column to the last column, the headers are obtained from ft_feature
colnames(df_General)[3:length(df_General)] <- as.character(ft_feature)
##############################################################
# *STEP 7: Data Analysis --> find mean based on subject and activity
# load data table package
library(data.table)
# create data table dt_General from df_General
dt_General <- data.table(df_General)
# take all columns except first two, split them by the couple (Subject - Activity), and find mean to each splitted group
# credit to: http://lamages.blogspot.com/2012/01/say-it-in-r-with-by-apply-and-friends.html
dt_Refined_General <- dt_General[,lapply(.SD,mean),by="Subject,Activity",.SDcols=3:length(dt_General)]
# reorder the rows based on Subject - Activity
dt_Refined_General <- dt_Refined_General[order(dt_Refined_General$Subject,dt_Refined_General$Activity),]
##############################################################
# STEP 8: Write to .txt file
write.table(dt_Refined_General, "tidy_data.txt", sep="\t", row.names = F, col.names = T)
setwd("~/Desktop/Coursera/Data_Science/datasciencecoursera")
setwd("~/Desktop/Coursera/Data_Science")
setwd("~/Desktop/Coursera/Data_Science/datasciencecoursera/Class_2/Week_4")
set.seed(1)
rpois(5,2)
set.seed(1)
rpois(5,2)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(y,x)
plot(x,y)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
set.seed(10)
x <- rbinom(10, 10, 0.5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
plot(x,y)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
